{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ed8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ccf91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from numpy import mean, absolute\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from os import listdir\n",
    "from pathlib import Path\n",
    "from os.path import isfile, join\n",
    "from natsort import natsorted ## !pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c30a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainFileName=\"xtrain_AWID_FeatureSelection_reduced.npy\"\n",
    "xtestFileName=\"xtest_AWID_FeatureSelection_reduced.npy\"\n",
    "ytrainFileName=\"ytrain_AWID_FeatureSelection_reduced.npy\"\n",
    "ytestFileName=\"ytest_AWID_FeatureSelection_reduced.npy\"\n",
    "X_train=np.load(xtrainFileName)\n",
    "X_test=np.load(xtestFileName)\n",
    "y_train=np.load(ytrainFileName)\n",
    "y_test=np.load(ytestFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5fda9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57573164, -0.19466678,  0.57611728, ..., -0.04813688,\n",
       "        -0.97198544, -0.55207137],\n",
       "       [-0.43783856, -0.29087712, -0.09255321, ..., -0.28251807,\n",
       "         1.05597342, -0.48071656],\n",
       "       [-0.32292766,  2.5879669 , -0.09255321, ..., -0.14188935,\n",
       "         1.05597342, -0.62342618],\n",
       "       ...,\n",
       "       [-0.32292766,  2.81718908, -0.09255321, ..., -0.23564183,\n",
       "         1.05597342, -1.26561948],\n",
       "       [ 1.92275963, -0.45678132, -0.04894427, ...,  2.14332723,\n",
       "         1.05597342,  1.01773447],\n",
       "       [-0.39844054, -0.28926337, -0.06389591, ..., -0.25907995,\n",
       "         1.05597342, -0.76613581]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf57ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95aaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler().fit(X_train)\n",
    "X_train_transformed=scaler.transform(X_train)\n",
    "X_test_transformed=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e682fc63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57244847, -0.83217363, -0.07427899, ..., -0.47002302,\n",
       "        -0.97198544, -0.76613581],\n",
       "       [-0.60199699, -0.01866551, -0.09213789, ..., -0.47002302,\n",
       "        -0.97198544, -1.4083291 ],\n",
       "       [-0.60199699,  0.04429943, -0.08009351, ..., -0.28251807,\n",
       "        -0.97198544,  0.51825079],\n",
       "       ...,\n",
       "       [ 1.82754774, -0.64503608, -0.07012576, ...,  0.46750174,\n",
       "         1.05597342,  1.01773447],\n",
       "       [ 1.87679527, -0.79560333,  0.04035024, ...,  0.67844481,\n",
       "         0.37998714,  1.08908928],\n",
       "       [-0.45753757, -0.63329279, -0.04146845, ..., -0.28251807,\n",
       "         1.05597342, -0.76613581]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079e02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5749377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4139d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "#onehotencoder1 = OneHotEncoder(categorical_features = [0])\n",
    "#y_train = onehotencoder1.fit_transform(y_train).toarray()\n",
    "#y_test = onehotencoder1.fit_transform(y_test).toarray()\n",
    "\n",
    "\n",
    "#y_train.\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01de2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train = encoder.fit_transform(y_train_df)\n",
    "y_test = encoder.fit_transform(y_test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb2428de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf67be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "keras = tf.keras  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import Constant\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02a2b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64,kernel_size=3,\n",
    "    strides=1,activation='relu', padding = 'same', input_shape=(X_train.shape[1], 1),name='Input'))\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], name='Dense_0', \n",
    "                #kernel_initializer='he_uniform', \n",
    "                 activation='PReLU'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dense(64, activation='PReLU', name='Dense_1'))\n",
    "model.add(Dense(32, activation='PReLU',name='Dense_2'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation='softmax', name='Output'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46a861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c86b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = X_train_transformed[:, :, np.newaxis]\n",
    "X_test_transformed = X_test_transformed[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c695d84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 19, 10)            110       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 10)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 100)            1100      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                5614      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,824\n",
      "Trainable params: 6,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "k1=10\n",
    "n1=X_train.shape[1]\n",
    "n2=n1-k1+1\n",
    "n3=4\n",
    "k2=math.ceil(n2/n3)\n",
    "n4=100\n",
    "\n",
    "#model_name=(dataset+'_1DCNN')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(k1, n2, activation='relu', padding = 'same', input_shape=(X_train.shape[1], 1)))\n",
    "#model.add(layers.Conv1D(128, 5, activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling1D(n3))\n",
    "model.add(Dense(n4, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "#model.add(layers.Conv1D(128, 5, activation='relu', padding = 'same'))\n",
    "#model.add(layers.Conv1D(128, 5, activation='relu', padding = 'same'))\n",
    "#model.add(layers.MaxPooling1D(2))\n",
    "#\n",
    "#model.add(layers.Flatten())\n",
    "#\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(128, activation='relu'))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "#\n",
    "#model.add(layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd69ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd=[]\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = [1,1]\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        sd.append(step_decay(len(self.losses)))\n",
    "        print('lr:', step_decay(len(self.losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26f2bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate = 0.1\n",
    "#decay_rate = 5e-6\n",
    "#momentum = 0.9\n",
    "#epochs=100\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "filepath='WNIDS_CNN_model_projec_FS.hdf5'\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.3, patience=50, verbose=1, cooldown=10, min_lr=1e-5)\n",
    "lr_shceduler = LearningRateScheduler(lambda _, lr: lr * np.exp(-0.01), verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b7f7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(losses):\n",
    "    if float(2*np.sqrt(np.array(history.losses[-1])))<0.3:\n",
    "        lrate=0.01*1/(1+0.1*len(history.losses))\n",
    "        momentum=0.8\n",
    "        decay_rate=2e-6\n",
    "        return lrate\n",
    "    else:\n",
    "        lrate=0.1\n",
    "        return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "482359eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history=LossHistory()\n",
    "#lrate=LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a394736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [reduce_lr, lr_shceduler,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cace6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model Summary: \n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 19, 10)            110       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 10)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4, 100)            1100      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                5614      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,824\n",
      "Trainable params: 6,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanjay\\anaconda3\\envs\\Projects_Segmentation\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Adam optimizer with learning rate of 0.001\n",
    "optimizer = Adam(lr=0.001)\n",
    "#optimizer=Adam(lr=lr_schedule(0))\n",
    "#optimizer='rmsprop'\n",
    "model.compile(optimizer, \n",
    "              #loss='binary_crossentropy',\n",
    "              loss='categorical_crossentropy', \n",
    "              #loss='mse', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Neural Network Model Summary: ')\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0009900498807740119.\n",
      "Epoch 1/100\n",
      "11684/11696 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9853\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.98992, saving model to WNIDS_CNN_model_projec_FS.hdf5\n",
      "11696/11696 [==============================] - 46s 3ms/step - loss: 0.0527 - accuracy: 0.9853 - val_loss: 0.0324 - val_accuracy: 0.9899 - lr: 9.9005e-04\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009801987522893801.\n",
      "Epoch 2/100\n",
      "11693/11696 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9907\n",
      "Epoch 00002: val_accuracy improved from 0.98992 to 0.99130, saving model to WNIDS_CNN_model_projec_FS.hdf5\n",
      "11696/11696 [==============================] - 39s 3ms/step - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.0268 - val_accuracy: 0.9913 - lr: 9.8020e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0009704455922292659.\n",
      "Epoch 3/100\n",
      "11694/11696 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9924\n",
      "Epoch 00003: val_accuracy improved from 0.99130 to 0.99187, saving model to WNIDS_CNN_model_projec_FS.hdf5\n",
      "11696/11696 [==============================] - 40s 3ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0227 - val_accuracy: 0.9919 - lr: 9.7045e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0009607894785379089.\n",
      "Epoch 4/100\n",
      "11693/11696 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 00004: val_accuracy improved from 0.99187 to 0.99299, saving model to WNIDS_CNN_model_projec_FS.hdf5\n",
      "11696/11696 [==============================] - 40s 3ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0198 - val_accuracy: 0.9930 - lr: 9.6079e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0009512294891595492.\n",
      "Epoch 5/100\n",
      "11690/11696 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9935\n",
      "Epoch 00005: val_accuracy improved from 0.99299 to 0.99348, saving model to WNIDS_CNN_model_projec_FS.hdf5\n",
      "11696/11696 [==============================] - 38s 3ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 0.0186 - val_accuracy: 0.9935 - lr: 9.5123e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0009417645867814564.\n",
      "Epoch 6/100\n",
      "11691/11696 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9938\n",
      "Epoch 00006: val_accuracy improved from 0.99348 to 0.99412, saving model to WNIDS_CNN_model_projec_FS.hdf5\n",
      "11696/11696 [==============================] - 39s 3ms/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.0169 - val_accuracy: 0.9941 - lr: 9.4176e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.0009323938493478706.\n",
      "Epoch 7/100\n",
      "11682/11696 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
      "Epoch 00007: val_accuracy did not improve from 0.99412\n",
      "11696/11696 [==============================] - 39s 3ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.0187 - val_accuracy: 0.9936 - lr: 9.3239e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009231163548030314.\n",
      "Epoch 8/100\n",
      " 9600/11696 [=======================>......] - ETA: 6s - loss: 0.0167 - accuracy: 0.9942"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start = time.time()\n",
    "model_history=model.fit(X_train_transformed, y_train, \n",
    "          verbose=1, \n",
    "          batch_size=128, \n",
    "          epochs=100, \n",
    "          validation_split=0.1,\n",
    "          callbacks=callbacks\n",
    "          #validation_data=(X_test, y_test)\n",
    "                       )\n",
    "end = time.time()\n",
    "print('Time elapsed: %.4f'%(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c92c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on unseen data\n",
    "model.load_weights(filepath)\n",
    "\n",
    "results = model.evaluate(X_test_transformed, y_test)\n",
    "\n",
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "WNIDS_model_df = pd.DataFrame(model_history.history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78224d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75647a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('WNIDS_model_cnn.csv', mode='w') as f:\n",
    "    WNIDS_model_df.to_csv(f)   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07dd7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_model = model_history\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history_model.history['loss']\n",
    "val_loss = history_model.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history_model.history['accuracy']\n",
    "#acc = history.history['accuracy']\n",
    "val_acc = history_model.history['val_accuracy']\n",
    "#val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bacb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions1=model.predict(X_test_transformed)\n",
    "predictions1 = predictions1.argmax(axis=-1)\n",
    "y_test=y_test.argmax(axis=-1)\n",
    "accuracy_model1=accuracy_score(y_test,predictions1)\n",
    "print(\"The accuray after the first classifier (4 classes)is: \")\n",
    "print(accuracy_model1)\n",
    "cm0=confusion_matrix(y_test,predictions1)\n",
    "cm0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a90a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c24b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Normal', 'Deauth', 'Disas', '(Re)Assoc',\n",
    "                            'RogueAP', 'Krack', 'Kr00k',\n",
    "                            'SSH', 'Botnet', 'Malware', 'SQL_Injection',\n",
    "                            'SSDP','Evil_Twin', 'Website_spoofing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0c3ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(36,16))\n",
    "plt.imshow(cm0, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "fmt = 'd'\n",
    "np.set_printoptions(precision=2)\n",
    "thresh = cm0.max() / 2.\n",
    "for i, j in itertools.product(range(cm0.shape[0]), range(cm0.shape[1])):\n",
    "    plt.text(j, i, format(cm0[i, j], fmt), size=16,\n",
    "             horizontalalignment=\"center\", color=\"white\" if cm0[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontweight='bold')\n",
    "    plt.xlabel('Predicted label', fontweight='bold')\n",
    "   \n",
    "plt.show()\n",
    "fig.savefig('confusion_matrix_4_classes_2.png',dpi=600)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8d6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr0 = classification_report(y_test, predictions1, target_names=classes)\n",
    "print(cr0)\n",
    "accuracy_0 = accuracy_score(y_test, predictions1)*100\n",
    "print(\"The accuray after the first classifier (4 classes)is: \",accuracy_0,\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eacbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras_visualizer import visualizer \n",
    "#visualizer(model, format='png', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f43173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import truediv\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0881b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_acc, av_acc=AA_andEachClassAccuracy(cm0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb37005",
   "metadata": {},
   "outputs": [],
   "source": [
    "each_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1be4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a4e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a35b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3bf9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
